---
title: "Drob_The_Office"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# install.packages('schrute')
library(schrute)
library(tidyverse)
library(tidytext)
theme_set(theme_light())

office_transcripts <- as_tibble(theoffice) %>% 
  mutate(season = as.integer(season),
         episode = as.integer(episode)) %>% 
  mutate(character = str_remove_all(character, '"')) %>%
  mutate(name = str_to_lower(str_remove_all(episode_name, "\\.| \\(Part.*")))

# office_transcripts2 <- as_tibble(theoffice) %>% 
#   mutate(season = as.integer(season),
#          episode = as.integer(episode)) %>% 
#   mutate(character = str_remove_all(character, '"'))
# 
# office_transcripts3 <- as_tibble(theoffice) %>% 
#   mutate(season = as.integer(season),
#          episode = as.integer(episode)) %>% 
#   mutate(character = str_remove_all(character, '"')) %>%
#   mutate(name = str_to_lower(str_remove_all(episode_name, "\\.| \\(Part.*")))



  
office_transcripts %>% 
  distinct(character) %>% 
  filter(str_detect(character, 'gela' ))

a1 <- office_transcripts%>% 
   mutate(name = str_to_lower(str_remove_all(episode_name, "\\.| \\(Part.*")))

office_ratings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-17/office_ratings.csv') %>% 
  mutate(name = str_to_lower(str_remove_all(title, "\\.| \\(Part.*|\\: Part.*")))
```

```{r}
office_ratings %>% 
  group_by(season) %>% 
  summarize(avg_rating = mean(imdb_rating)) %>% 
  ggplot(aes(season, avg_rating))+
  geom_line() +
  scale_x_continuous(breaks = 1:9)

office_ratings %>% 
  mutate(title = fct_inorder(title)) %>% 
  ggplot(aes(title, imdb_rating))+
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

office_ratings %>% 
  mutate(title = fct_inorder(title)) %>% 
  ggplot(aes(title, imdb_rating, fill = factor(season)))+
  geom_col() +
  theme(axis.text.x = element_blank())

office_ratings %>% 
  mutate(title = fct_inorder(title)) %>% 
  ggplot(aes(title, imdb_rating)) +
  geom_line(group = 1) +
  geom_point(aes(color = factor(season), size = total_votes)) +
  geom_text(aes(label = title), check_overlap = TRUE) +
  theme(axis.text.x = element_blank(),
        panel.grid.major.x = element_blank(),
        legend.position = 'none')

office_ratings %>% 
  mutate(title = fct_inorder(title),
         episode_number = row_number()) %>% 
  ggplot(aes(episode_number, imdb_rating)) +
  geom_line() +
  geom_smooth()+
  geom_point(aes(color = factor(season), size = total_votes)) +
  geom_text(aes(label = title), check_overlap = TRUE, hjust = 1) +
  expand_limits(x = -10) +
  theme(axis.text.x = element_blank(),
        panel.grid.major.x = element_blank(),
        legend.position = 'none') +
  labs(x = 'Episode',
       y = 'IMDB',
       title = 'Popularity',
       subtitle = 'Color and Size')

office_ratings %>% 
  arrange(desc(imdb_rating)) %>% 
  mutate(title = paste0(season, '.', episode, ' ', title),
         title = fct_reorder(title, imdb_rating)) %>% 
  head(20) %>% 
  ggplot(aes(title, imdb_rating, color = factor(season), size = total_votes))+
  geom_point()+
  coord_flip()+
  labs(color = 'S.e.a.s.o.n', 
       title = 'Most Popular')
```

### Transcripts

```{r}
blacklist <- c('yeah', 'uh', 'hey', 'gonna')
blacklist_character <- c('Group', 'All', 'Everyone', 'Guy', 'Girl', 'Both' )

transcript_words <- office_transcripts %>% 
  group_by(character) %>% 
  filter(n()>=100,
         n_distinct(episode_name) > 2) %>% 
  ungroup() %>% 
  select(-text_w_direction) %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words, by = 'word') %>% 
  filter(!word %in% blacklist,
         !character %in% blacklist_character)

transcript_words %>% 
  count(character, word)

transcript_words %>% 
  count(character, sort = TRUE)

transcript_words %>% 
  add_count(word) %>% 
  filter(n >= 20) %>% 
  count(word, character) %>% 
  bind_tf_idf(word, character, n) %>% 
  arrange(desc(tf_idf))

transcript_words %>% 
  count(character, sort = TRUE)


character_tf_idf <- transcript_words %>% 
  add_count(word) %>% 
  filter(n >= 20) %>% 
  count(word, character) %>% 
  bind_tf_idf(word, character, n) %>% 
  arrange(desc(tf_idf))

character_tf_idf %>% 
  filter(character %in% c('Dwight', 'Jim', 'Michael', 'Darryl', 'Holly', 'Jan')) %>% 
  group_by(character) %>% 
  top_n(10, tf_idf) %>% 
  ungroup() %>% 
  mutate(word = reorder_within(word, tf_idf, character)) %>%
  # head(20) %>% 
  ggplot(aes(word, tf_idf)) +
  geom_col() +
  coord_flip() +
  scale_x_reordered() +
  facet_wrap(~ character, scales = 'free_y')+
  labs(x = "",
       y = 'tf-idf')

office_transcripts %>% filter(str_detect(text, 'pum ')) %>% View()

office_transcripts %>% 
  count(character, sort = TRUE)
```


### Mach Learning

```{r}
office_transcripts %>% 
  count(episode_name, character) %>% 
  distinct(episode_name) %>% 
  anti_join(office_ratings, by = c(episode_name = 'title'))

office_transcripts %>% 
  count(season, episode) %>% 
  anti_join(office_ratings, by = c('season', 'episode'))

office_transcripts %>% 
  count(season, episode, episode_name) %>% 
  filter(season == 4)

office_ratings %>% 
  count(season, episode, title) %>% 
  filter(season == 4)

office_transcripts %>% 
  distinct(name) %>%
  anti_join(office_ratings, by = 'name')

office_ratings %>% 
  group_by(name) %>% 
  summarize(imdb_rating = mean(imdb_rating)) %>% 
  count(name, sort = T) %>% 
  distinct(name) %>%
  anti_join(office_transcripts, by = 'name')

ratings_summarized <- office_ratings %>% 
  group_by(name) %>% 
  summarize(imdb_rating = mean(imdb_rating))

x0 <- office_transcripts %>% 
  count(character, name) %>% 
  group_by(character)

x1 <- office_transcripts %>% 
  count(character, name) %>% 
  group_by(character) %>% 
  filter(n>=100) # aparece só os characters com mais de 100 falas em um episódio

x2 <- office_transcripts %>% 
  count(character, name) %>% 
  group_by(character) %>% 
  filter(sum(n)>=100) # aparece todos os characters com mais de 100 falas em quaisquer episódios

character_lines_ratings <- office_transcripts %>% 
  count(character, name) %>% 
  group_by(character) %>% 
  filter(sum(n)>=100) %>% 
  inner_join(ratings_summarized, by = 'name') 

character_lines_ratings <- office_transcripts %>% 
  filter(!character %in% blacklist_character) %>% 
  count(character, name) %>% 
  group_by(character) %>% 
  filter(sum(n)>=50,
         n()>= 5) %>% 
  inner_join(ratings_summarized, by = 'name') 

character_lines_ratings %>% 
  summarize(avg_ratings = mean(imdb_rating),
            nb_episodes = n()) %>% 
  arrange(desc(avg_ratings))%>% 
  View()
```

```{r}
director_writer_features <- office_transcripts %>% 
  distinct(name, director, writer) %>% 
  gather(type, value, director, writer) %>% 
  separate_rows(value, sep = ';') %>% 
  unite(feature, type, value, sep = ': ') %>% 
  group_by(feature) %>% 
  filter(n() >= 3) %>% 
  mutate(value = 1) %>% 
  ungroup()

character_line_features <- character_lines_ratings %>% 
  ungroup() %>% 
  transmute(name, feature = character, value = log2(n))

season_features = office_ratings %>% 
  distinct(name, season) %>% 
  transmute(name, feature = paste('season:', season), value = 1)

ggplot(character_lines_ratings, aes(n))+geom_histogram()

ggplot(character_lines_ratings, aes(n))+geom_histogram() + scale_x_log10()

features <- bind_rows(director_writer_features, 
                      character_line_features,
                      season_features) %>% 
  semi_join(office_ratings, by = 'name') %>% 
  semi_join(office_transcripts, by = 'name')

episode_feature_matrix <- features %>% 
  cast_sparse(name, feature, value)

dim(episode_feature_matrix)

rownames(episode_feature_matrix)

ratings <- ratings_summarized$imdb_rating[match(rownames(episode_feature_matrix), ratings_summarized$name)]

#install.packages('glmnet')
library(glmnet)
library(broom)

mod <- cv.glmnet(episode_feature_matrix, ratings)

plot(mod)

tidy(mod$glmnet.fit) %>%
  filter(lambda == mod$lambda.min,
         term != "(Intercept)") %>%
  mutate(term = fct_reorder(term, estimate)) %>%
  ggplot(aes(term, estimate, fill = estimate > 0)) +
  geom_col() +
  coord_flip() +
  labs(y = "Estimated effect on the rating of an episode") +
  theme(legend.position = "none")
```
